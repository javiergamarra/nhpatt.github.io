---
id: 938
title: Arreglando chapuzas en Android (un caso pr谩ctico)
date: 2014-03-13T12:00:09+00:00
author: nhpatt
layout: post
guid: http://nhpatt.com/arreglando-chapuzas-en-android/
permalink: /arreglando-chapuzas-en-android/
categories:
  - dev
  - java
---
Desvi谩ndome un poco de mi trabajo de estos 煤ltimos meses, me han pedido ayuda t茅cnica en una aplicaci贸n Android.

Os pongo en situaci贸n: la aplicaci贸n llama a un WS pidiendo 300 objetos a actualizar, parsea el resultado, lo transforma a objetos, inserta/actualiza y vuelve a ver si hay m谩s resultados (y repite el proceso si es as铆). Hay muchos resultados (+4000) por lo que tarda **105 segundos!**En un Nexus 5. Y hay m谩s objetos a actualizar!

Es una barbaridad de tiempo pero tienen la suerte de que los usuarios**necesitan** la aplicaci贸n por lo que pacientemente esperan hasta que termina la actualizaci贸n (que se repite cada 2-3 meses). Tambi茅n les sirve de consuelo la cantidad de aplicaciones que hacen esperar esos tiempos para actualizaciones de datos u otras cosas que podr铆an ser hechas en el backend (Skype, te miro a ti).

Veamos a ver lo que puedo hacer sin cambiar dr谩sticamente el enfoque (rock-the-boat no permitidos):

  * Antes de empezar limpio c贸digo que no se usa, incluyendopasar el contexto al servicio web****para no usarlo nunca. Resultado**103**segundos (bien puede ser cero la mejora, por desviaci贸n).

  * Veo que para insertar/actualizar primero hacen una consulta para ver si est谩 en BD el dato y actuar en consecuencia. OrmLiteincluye una forma de hacerlo autom谩ticamente:**[insertWithOnConflict](http://developer.android.com/reference/android/database/sqlite/SQLiteDatabase.html#insertWithOnConflict(java.lang.String, java.lang.String, android.content.ContentValues, int))**(con flag [replace](http://developer.android.com/reference/android/database/sqlite/SQLiteDatabase.html#CONFLICT_REPLACE)) mucho m谩s eficiente en inserciones y algo en actualizaciones. Estome permite quitar una select, un insert/update y no abrir la base de datos en modo lectura ->**93**segundos.

  * Por defecto OrmLiteabre una transacci贸n por cada operaci贸n. Obviamente ( :( ) no han utilizado una para cada conjunto de datos (o global). Si abro**una 煤nica transacci贸n** ->**52**segundos.

  * Tal como est谩 el c贸digo, se parsea a lista de JSONObject y se transforma el resultado en objetos propios (adem谩s se aplican regex para quitar caracteres). Si**trabajamos directamente con la lista de JSONObject**->**42**segundos.

  * Al analizar d贸nde se va el tiempo, veo que hay muchas llamadas al garbage collector (porque hay muchos objetos creados), al analizar la clase que parsea veo que**est谩 mal el parseo de los objetos**(se vuelven a parsear JSONObjects innecesariamente), cambio el c贸digo para trabajar con JSONArray directamente ->**22**segundos.

  * No entiendo bien porque se hace la operaci贸n en bucle (imagino que c贸mo gesti贸n simple de memoria), cambio el c贸digo para ques贸lo se haga una vez ->**15**segundos.

  * Quito c贸digo que no me gusta, elimino creaci贸n de objetos varios en bucles ->**13**segundos.

Los 13 segundos actuales se desglosan en las siguientes operaciones:

  * 4 segundos recuperando del WS y parseando.
  * 6 segundos guardando (4000 objetos!).
  * 3 segundos actualizando la fecha de consulta del WS!!! -> Esta operaci贸n es**incre铆blemente ineficiente**(veo r谩pidamente que parece que es actualizar una fila y consultar) pero c贸mo es poco tiempo,lo ignoro de momento.

**Pero**, en el camino de la eficiencia me he cargado la aplicaci贸n de una regex para quitar caracteres err贸neos, tengo que volver a incluirlo:

  * Hago unas mejoras previas, creando menos objetos ->**12**segundos.

  * A帽ado la regex tal como estaba, aplicada por cada objeto ->**30**segundos :(

  * La regex puede mejorarse**compilando el patr贸n**antes de aplicarla ->**22**segundos (son demasiados).

  * Soy idiota, deber铆a aplicar las regex a toda la response (en vez de trozo a trozo) ->**13**segundos. Lo mejor es que no se si las regex son necesarias para estos datos, porque se buscan caracteres alfanum茅ricos y los resultados (que tengo) son s贸lo n煤meros!!!! pero a煤n as铆 la dejo&#8230;

  * Por 煤ltimo,**lanzo la aplicaci贸n en modo ejecuci贸n (no debug)**, resultado ->**5 segundos**. El desglose es el siguiente:

  * 2 segundos recuperando del WS y parseando.
  * 1 segundo guardando.
  * 2 segundos actualizando la fecha!!! (sigue siendo demasiado, este c贸digo est谩 mal).

**Resultado final: 5 segundos&#8230;** partiendo de 105.

Mi enfoque siempre ha sido ver lo que tarda m谩s (con DDMS, trace y c贸digo) y atacar, teniendo en cuenta los mensajes del GC en el log. El resultado final tambi茅n han sido 60 l铆neas de c贸digo menos (en 132 se ha quedado).

Hay m谩s mejoras posibles (en [SO](http://stackoverflow.com/questions/1711631/improve-insert-per-second-performance-of-sqlite)hay un listado curioso) pero de momento as铆 se queda, esperando feedback del resto del equipo.

Nada m谩s, estoy abierto a cualquier sugerencia! (seguro que se me ha pasado algo) 

